# ğŸ’¡ GreenTech Solutions

> _ModÃ©lisation et visualisation des performances Ã©nergÃ©tiques des logements en France_
>
> Projet rÃ©alisÃ© dans le cadre du Master 2 **SISE â€“ Statistique et Informatique pour la Science des donnÃ©Es (Lyon 2)**  
> AnnÃ©e universitaire 2025-2026

---

## Objectif du projet

**GreenTech Solutions** vise Ã  construire une chaÃ®ne complÃ¨te d'analyse et de prÃ©diction Ã  partir des donnÃ©es publiques des **Diagnostics de Performance Ã‰nergÃ©tique (DPE)**.

Le projet couvre toutes les Ã©tapes du cycle de la donnÃ©e :

1. **Extraction et nettoyage** des donnÃ©es ADEME (DPE existants & neufs)  
2. **Analyse exploratoire et modÃ©lisation** (classification & rÃ©gression)  
3. **DÃ©ploiement** d'une application web interactive sous **Streamlit**  
4. **Documentation** technique et fonctionnelle complÃ¨tes

---

## Architecture du dÃ©pÃ´t

```text
m2_enedis/
â”œâ”€â”€ app/                     # code principal de l'application Streamlit
â”‚   â”œâ”€â”€ app.py               # point d'entrÃ©e de l'application (lancement local ou Render)
â”‚   â”œâ”€â”€ pages/               # pages multipages Streamlit (Contexte, Carte, PrÃ©diction, etc.)
â”‚   â”œâ”€â”€ components/          # petits modules rÃ©utilisables : graphiques, filtres, exports...
â”‚   â”œâ”€â”€ model/               # modÃ¨les entraÃ®nÃ©s (fichiers .pkl / .joblib)
â”‚   â”œâ”€â”€ utils/               # fonctions d'aide : prÃ©traitement, calculs, API, logs...
â”‚   â”œâ”€â”€ assets/              # feuilles CSS, icÃ´nes, images
â”‚   â””â”€â”€ styles/              # thÃ¨me ou fichiers de configuration Streamlit (.toml / .css)
â”‚
â”œâ”€â”€ data/                    # jeux de donnÃ©es utilisÃ©s
â”‚   â”œâ”€â”€ raw/                 # donnÃ©es brutes ADEME tÃ©lÃ©chargÃ©es (DPE existants et neufs)
â”‚   â””â”€â”€ processed/           # donnÃ©es nettoyÃ©es, enrichies, prÃªtes Ã  l'analyse ou Ã  la modÃ©lisation
â”‚
â”œâ”€â”€ notebooks/               # analyses exploratoires et modÃ©lisation (Jupyter)
â”‚   â”œâ”€â”€ exploration.ipynb
â”‚   â”œâ”€â”€ classification.ipynb
â”‚   â””â”€â”€ regression.ipynb
â”‚
â”œâ”€â”€ docker/                  # conteneurisation de l'application
â”‚   â””â”€â”€ Dockerfile           # instructions pour construire l'image Docker
â”‚
â”œâ”€â”€ docs/                    # documentation complÃ¨te du projet
â”‚   â”œâ”€â”€ doc_technique.md     # â‰¤ 2 pages : installation, architecture, dÃ©pendances
â”‚   â”œâ”€â”€ doc_fonctionnelle.md # â‰¤ 2 pages : pages, fonctionnalitÃ©s, parcours utilisateur
â”‚   â”œâ”€â”€ rapport_ml.md        # 4-6 pages : contexte, modÃ¨les, rÃ©sultats, interprÃ©tation
â”‚   â”œâ”€â”€ SRS_TRACE.md         # matrice de traÃ§abilitÃ© du cahier des charges
â”‚   â”œâ”€â”€ SCRUM_GITHUB_CHECKLIST.md  # suivi organisationnel et qualitÃ© (Scrum / GitHub)
â”‚   â””â”€â”€ assets/              # schÃ©mas Draw.io, captures d'Ã©cran, logos
â”‚
â”œâ”€â”€ tests/                   # vÃ©rifications minimales
â”‚   â””â”€â”€ smoke_test.py        # "smoke test" : s'assure que les imports se font sans erreur
â”‚
â”œâ”€â”€ requirements.txt         # liste des librairies Python nÃ©cessaires
â”œâ”€â”€ Procfile                 # commande exÃ©cutÃ©e sur Render / Heroku (dÃ©ploiement automatique)
â”œâ”€â”€ runtime.txt              # version Python utilisÃ©e
â”œâ”€â”€ README.md                # ce fichier : prÃ©sentation du projet
â””â”€â”€ LICENSE
```

---

## Stack technique

| Domaine | Outils |
|----------|--------|
| Langage principal | Python 3.10+ |
| Data & ML | pandas, numpy, scikit-learn |
| Visualisation | Plotly Express, Streamlit |
| API & dÃ©ploiement | requests, Render / Heroku |
| Conteneurisation | Docker |
| Collaboration | GitHub, Taiga (Scrum) |

---

## Ã‰quipe & rÃ´les

| Membre | RÃ´le principal | RÃ´les secondaires |
|---------|----------------|-------------------|
| **Nico Dena** | Responsable data & intÃ©gration | ModÃ©lisation, documentation |
| **Modou Mboup** | Responsable ML & qualitÃ© | Interface, dÃ©ploiement |
| **Rina Razafimahefa** | Responsable Interface & Design | Data, documentation |

> Chaque membre a contribuÃ© Ã  plusieurs volets : la rÃ©partition est indicative mais reflÃ¨te la spÃ©cialisation de chacun.

---

## Organisation agile

- Outil de gestion : [Taiga.io](https://tree.taiga.io/) â€“ MÃ©thode **Scrum**  
- Backlog structurÃ© en 6 Ã‰pics : Data / ML / Interface / DÃ©ploiement / Documentation / Gestion  
- Sprints hebdomadaires avec **revue et rÃ©trospective** Ã  chaque fin de sprint  

---

## Livrables clÃ©s

| Type | Fichier / dossier |
|-------|-------------------|
| Dataset final | `data/processed/dpe_full.parquet` |
| ModÃ¨les | `app/model/classification_model.pkl`, `app/model/regression_model.pkl` |
| Application Dash | `app/app.py` |
| Documentation technique | `docs/doc_technique.md` |
| Documentation fonctionnelle | `docs/doc_fonctionnelle.md` |
| Rapport ML | `docs/rapport_ml.md` |
| Matrice de conformitÃ© | `docs/SRS_TRACE.md` |

---

## Installation locale

```bash
# 1. Cloner le dÃ©pÃ´t
git clone https://github.com/<votre_repo>.git
cd <votre_repo>

# 2. CrÃ©er l'environnement virtuel
python -m venv venv
source venv\Scripts\activate  # ou venv/bin/activate sous MacOS

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Lancer l'application Dash
python app/app.py
```

---

## DÃ©ploiement

L'application est hÃ©bergÃ©e sur **Render** :  
ğŸ”— [Lien vers l'application dÃ©ployÃ©e](https://...)  

Endpoints disponibles :
- `/predict` â†’ prÃ©diction DPE + consommation  
- `/health` â†’ vÃ©rification du service  
- `/retrain` â†’ rÃ©entraÃ®nement du modÃ¨le

---

### ğŸ“Š Statut du projet

| Sprint | Ã‰tat | Avancement |
|---------|------|-------------|
| Sprint 1 - Data Foundation | âœ… TerminÃ© | 100 % |
| Sprint 2 - Model Building | ğŸ”„ En cours | 20 % |
| Sprint 3 - Deployment & API | ğŸ”„ En cours | 20 % |
| Sprint 4 - Final Delivery | ğŸ”œ Ã€ venir | - |
