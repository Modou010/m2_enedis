<<<<<<< HEAD
# üåø GreenTech Solutions - Dashboard √ânerg√©tique

Application Streamlit d'analyse des donn√©es √©nerg√©tiques ADEME et Enedis.
=======
# üí° GreenTech Solutions

> _Mod√©lisation et visualisation des performances √©nerg√©tiques des logements en France_
>
> Projet r√©alis√© dans le cadre du Master 2 **SISE ‚Äì Statistique et Informatique pour la Science des donn√©Es (Lyon 2)**  
> Ann√©e universitaire 2025-2026
> 
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
---

## Objectif du projet

L'objectif de **GreenTech Solutions** est de construire une cha√Æne compl√®te d'analyse et de pr√©diction √† partir des donn√©es publiques des **Diagnostics de Performance √ânerg√©tique (DPE)**.

Le projet couvre toutes les √©tapes du cycle de la donn√©e :

1. **Extraction et nettoyage** des donn√©es ADEME (DPE existants & neufs)  
2. **Analyse exploratoire et mod√©lisation** (classification & r√©gression)  
3. **D√©ploiement** d'une application web interactive sous **Streamlit**  
4. **Documentation** technique et fonctionnelle

---


## üöÄ Fonctionnalit√©s

### Interface Utilisateur (Streamlit)
-  **Tableau de bord** : Visualisation interactive des donn√©es DPE
-  **Analyse** : Analyses statistiques approfondies
-  **Enedis** : Int√©gration des donn√©es de consommation Enedis
-  **Pr√©diction** : Pr√©diction d'√©tiquette DPE et de co√ªts √©nerg√©tiques
-  API : mise √† disposition de donn√©es et de mod√®les √† travers une API
-  **Rafra√Æchissement des donn√©es** : Mise √† jour automatique depuis l'API ADEME
-  **R√©entra√Ænement des mod√®les** : R√©entra√Ænement des mod√®les ML avec nouvelles donn√©es

### API REST (FastAPI)
-  **Pr√©dictions individuelles** : Endpoint `/predict`
-  **Pr√©dictions par lot** : Endpoint `/predict/batch`
-  **M√©triques des mod√®les** : Endpoint `/models/metrics`
-  **Rafra√Æchissement des donn√©es** : Endpoint `/data/refresh`
-  **R√©entra√Ænement** : Endpoint `/models/retrain`
>>>>>>> 6d7b8eb60e07cb371d6f937da3311d6eed4bfc80

##  Pr√©requis

- Docker Desktop install√©
- Docker Compose
- 4 GB RAM minimum

<<<<<<< HEAD
## üöÄ Installation rapide
=======
---

##  Structure du projet

```
greentech-solutions/
‚îú‚îÄ‚îÄ Data/                                               # Donn√©es provenant des Apis
‚îú   ‚îú‚îÄ‚îÄdata_ademe_existants_69.csv
‚îÇ   ‚îú‚îÄ‚îÄdata_ademe_existants_69.csv
‚îÇ   ‚îú‚îÄ‚îÄdonnees_enedis_69_.csv                           # Application Streamlit principale
‚îú‚îÄ‚îÄ Notebooks/
‚îú   ‚îú‚îÄ‚îÄ1_extraction_preparation_donnees.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ2_exploration_donnees.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ3_classification_regression.ipynb
‚îú‚îÄ‚îÄ streamlit/
|   ‚îú‚îÄ‚îÄ app.py                          # Application Streamlit principale
|   ‚îú‚îÄ‚îÄ pages/                          # Pages Streamlit
|   ‚îÇ   ‚îú‚îÄ‚îÄ welcome.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ home.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ analysis.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ enedis.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ prediction.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ compare.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ about.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ refresh_data.py            
|   ‚îÇ   ‚îî‚îÄ‚îÄ retrain_models.py          
|   ‚îú‚îÄ‚îÄ utils/                         # Modules utilitaires
|   ‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ model_utils.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ data_refresher.py          
|   ‚îÇ   ‚îî‚îÄ‚îÄ model_trainer.py           
|   ‚îú‚îÄ‚îÄ api/                           # API FastAPI
|   ‚îÇ   ‚îî‚îÄ‚îÄ main.py                    
|   ‚îú‚îÄ‚îÄ models/                        # Mod√®les ML sauvegard√©s
|   ‚îÇ   ‚îú‚îÄ‚îÄ classification_model.pkl
|   ‚îÇ   ‚îú‚îÄ‚îÄ regression_model.pkl
|   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.json
|   ‚îú‚îÄ‚îÄ data/                          # Donn√©es
|   ‚îÇ   ‚îú‚îÄ‚îÄ donnees_ademe_finales_nettoyees_69_final_pret.csv
|   ‚îÇ   ‚îú‚îÄ‚îÄdonnees_enedis_69_finales.csv
|   ‚îÇ   ‚îú‚îÄ‚îÄ adresses-69.csv
|   ‚îÇ   ‚îî‚îÄ‚îÄ metadata.json
|   ‚îú‚îÄ‚îÄ app.py                          # Application Streamlit principale
|   ‚îú‚îÄ‚îÄ pages/                          # Pages Streamlit
|   ‚îÇ   ‚îú‚îÄ‚îÄ welcome.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ home.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ analysis.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ enedis.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ prediction.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ compare.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ about.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ refresh_data.py            
|   ‚îÇ   ‚îî‚îÄ‚îÄ retrain_models.py          
|   ‚îú‚îÄ‚îÄ utils/                         # Modules utilitaires
|   ‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ model_utils.py
|   ‚îÇ   ‚îú‚îÄ‚îÄ data_refresher.py          
|   ‚îÇ   ‚îî‚îÄ‚îÄ model_trainer.py           
|   ‚îú‚îÄ‚îÄ api/                           # API FastAPI
|   ‚îÇ   ‚îî‚îÄ‚îÄ main.py                    
|   ‚îú‚îÄ‚îÄ models/                        # Mod√®les ML sauvegard√©s
|   ‚îÇ   ‚îú‚îÄ‚îÄ classification_model.pkl
|   ‚îÇ   ‚îú‚îÄ‚îÄ regression_model.pkl
|   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.json
|   ‚îú‚îÄ‚îÄ data/                          # Donn√©es application
|   ‚îÇ   ‚îú‚îÄ‚îÄ donnees_ademe_finales_nettoyees_69_final_pret.csv
|   ‚îÇ   ‚îú‚îÄ‚îÄdonnees_enedis_69_finales.csv
|   ‚îÇ   ‚îú‚îÄ‚îÄ adresses-69.csv
|   ‚îÇ   ‚îî‚îÄ‚îÄ metadata.json
‚îú‚îÄ‚îÄ Dockerfile                     
‚îú‚îÄ‚îÄ docker-compose.yml             
‚îú‚îÄ‚îÄ docker-entrypoint.sh           
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .dockerignore                  
‚îî‚îÄ‚îÄ README.md
```
<p align="center"><img src="schema_archicture_projet.jpg" alt="Sch√©ma d‚Äôarchitecture du projet" width="80%"></p>



## Stack technique

| Domaine | Outils |
|----------|--------|
| Langage principal | Python 3.10+ |
| Data & ML | pandas, numpy, scikit-learn |
| Visualisation | Plotly Express, Streamlit |
| API & d√©ploiement | FastAPI, unicorn, Render |
| Conteneurisation | Docker |
| Collaboration | GitHub, Taiga (Scrum) |

---

## √âquipe & r√¥les

| Membre | R√¥le principal | R√¥les secondaires |
|---------|----------------|-------------------|
| **Nico Dena** | Responsable data & int√©gration |Ingestion, Mod√©lisation et documentation |
| **Modou Mboup** | Responsable ML & qualit√© | Interface, d√©ploiement |
| **Rina Razafimahefa** | Responsable interface & design | Data, documentation |

> Chaque membre a contribu√© √† plusieurs volets du projet : la r√©partition est indicative mais la production a √©t√© collective et it√©rative selon les sprints.

---

## Organisation agile

- Outil de gestion : [Taiga.io](https://tree.taiga.io/) ‚Äì M√©thode **Scrum**  
- Backlog structur√© en 6 √âpics : Data / ML / Interface / D√©ploiement / Documentation / Gestion  
- Sprints hebdomadaires (burndown suivi automatiquement)  
- Revue et r√©trospective √† chaque fin de sprint  

---

## Livrables cl√©s

| Type | Fichier / dossier |
|-------|-------------------|
| Dataset final | `Data/donnees_ademe_finales_nettoyees_69_final_pret.csv`, `Data/donnees_enedis_69_finales.csv` |
| Mod√®les | `streamlit/models/classification_model.pkl`, `streamlit/models/regression_model.pkl` |
| Application Streamlit | `streamlit/app.py` |
| Documentation technique | `docs/doc_technique.md` |
| Documentation fonctionnelle | `docs/doc_fonctionnelle.md` |
| Rapport ML | `docs/rapport_ml.md` |
| Vid√©o d√©mo | üîó _[Lien √† venir]_ |

---


## üõ†Ô∏è Installation
>>>>>>> 6d7b8eb60e07cb371d6f937da3311d6eed4bfc80

### Option 1 : Avec Docker (Recommand√©)

```bash
<<<<<<< HEAD
# 1. Cloner le projet
git clone https://github.com/votre-username/greentech-project.git
cd greentech-project
=======
# Cloner le d√©p√¥t
git clone https://github.com/Modou010/m2_enedis.git
cd greentech-solutions
>>>>>>> 6d7b8eb60e07cb371d6f937da3311d6eed4bfc80

# 2. D√©marrer l'application
docker-compose up -d streamlit

# 3. Acc√©der √† l'application
# Streamlit : http://localhost:8502
# API : http://localhost:8000 (optionnel)
```

### Option 2 : Sans Docker (Local)

```bash
# 1. Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# .\venv\Scripts\activate  # Windows

# 2. Installer les d√©pendances
pip install -r requirements.txt

# 3. Lancer Streamlit
streamlit run app.py
```

<<<<<<< HEAD
## üìÅ Structure du projet

```
greentech-project/
‚îú‚îÄ‚îÄ app.py                 # Application principale
‚îú‚îÄ‚îÄ pages/                 # Pages Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ analysis.py       # Analyses ADEME
‚îÇ   ‚îú‚îÄ‚îÄ enedis.py         # Analyses Enedis
‚îÇ   ‚îî‚îÄ‚îÄ about.py          # √Ä propos
‚îú‚îÄ‚îÄ data/                  # Donn√©es CSV
‚îú‚îÄ‚îÄ models/                # Mod√®les ML
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ requirements.txt
```

## üõ†Ô∏è Commandes utiles

### Avec Make
=======
### Option 2 : Avec Docker (Recommand√©)

```bash
# Construire et lancer les services
docker-compose up -d

# Voir les logs
docker-compose logs -f

# Arr√™ter les services
docker-compose down
```

##  Acc√®s aux services

Une fois lanc√© :

- **Interface Streamlit** : [http://localhost:8501](http://localhost:8501)
- **API FastAPI** : [http://localhost:8000](http://localhost:8000)
- **Documentation API** : [http://localhost:8000/docs](http://localhost:8000/docs)

## Rafra√Æchissement des donn√©es

### Via l'interface Streamlit
1. Aller dans " Rafra√Æchir donn√©es"
2. Choisir le mode (nouveaux DPE uniquement ou rechargement complet)
3. Cliquer sur "Lancer le rafra√Æchissement"
>>>>>>> 6d7b8eb60e07cb371d6f937da3311d6eed4bfc80

```bash
make build          # Construire les images
make streamlit      # D√©marrer Streamlit
make logs           # Voir les logs
make down           # Tout arr√™ter
make clean          # Nettoyer
```

<<<<<<< HEAD
### Avec Docker Compose

=======
## R√©entra√Ænement des mod√®les

### Via l'interface Streamlit
1. Aller dans " R√©entra√Æner mod√®les"
2. Configurer les hyperparam√®tres (optionnel)
3. Cliquer sur "Lancer l'entra√Ænement"

### Via l'API
>>>>>>> 6d7b8eb60e07cb371d6f937da3311d6eed4bfc80
```bash
docker-compose up -d streamlit       # D√©marrer
docker-compose logs -f streamlit     # Logs en temps r√©el
docker-compose restart streamlit     # Red√©marrer
docker-compose down                  # Arr√™ter
```

## üîß D√©veloppement

### Mode hot-reload

D√©commentez dans `docker-compose.yml` :

```yaml
volumes:
  - ./pages:/app/pages
  - ./app.py:/app/app.py
```

Les modifications seront prises en compte automatiquement !

### Reconstruire apr√®s modifications

```bash
docker-compose up -d --build streamlit
```

## üìä Acc√®s aux services

| Service   | URL                        | Description          |
| --------- | -------------------------- | -------------------- |
| Streamlit | http://localhost:8502      | Interface principale |
| API       | http://localhost:8000      | API REST (optionnel) |
| Swagger   | http://localhost:8000/docs | Documentation API    |

## üêõ R√©solution de probl√®mes

### Port d√©j√† utilis√©

```bash
# Changer le port dans docker-compose.yml
ports:
  - "8503:8501"  # Utiliser 8503
```

### Logs pour d√©boguer

```bash
docker-compose logs -f streamlit
```

<<<<<<< HEAD
### Red√©marrage complet

```bash
docker-compose down -v
docker-compose build --no-cache
docker-compose up -d streamlit
```

## üì¶ Donn√©es requises

Placez vos fichiers CSV dans le dossier `data/` :

- `donnees_ademe_finales_nettoyees_69_final_pret.csv`
- `donnees_enedis_finales_69.csv`
=======
## üìä Mod√®les de Machine Learning

### Mod√®le de Classification
- **Algorithme** : Random Forest Classifier
- **Objectif** : Pr√©dire l'√©tiquette DPE (A, B, C, D, E, F, G)
- **Performance** : ~96% accuracy

### Mod√®le de R√©gression
- **Algorithme** : DecisionTree Regressor
- **Objectif** : Pr√©dire le co√ªt total des 5 usages (‚Ç¨/an)
- **Performance** : R¬≤ > 0.97
>>>>>>> 6d7b8eb60e07cb371d6f937da3311d6eed4bfc80

## üë• Contribution

<<<<<<< HEAD
1. Fork le projet
2. Cr√©er une branche (`git checkout -b feature/amelioration`)
3. Commit (`git commit -m 'Ajout fonctionnalit√©'`)
4. Push (`git push origin feature/amelioration`)
5. Ouvrir une Pull Request

## üìù License

MIT License

## üë®‚Äçüíª Auteur

Modou Mboup - M2 Projet √ânerg√©tique 2025

---

**Note** : Pour toute question, ouvrir une issue sur GitHub.
=======
## ü§ù Contribution

Les contributions sont les bienvenues ! N'h√©sitez pas √† ouvrir une issue ou une pull request, ou √† nous laisser un message

## üìÑ Licence

Ce projet est sous licence MIT.

## Contact

Pour toute question, contactez l'√©quipe GreenTech Solutions : franckdena@gmail.com, mboupmodou05@gmail.com, n.razafimahefa@univ-lyon2.fr

---

**Version** : 1.0.0  
**Derni√®re mise √† jour** : 2025
>>>>>>> 6d7b8eb60e07cb371d6f937da3311d6eed4bfc80
